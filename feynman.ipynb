{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pennylane as qml\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"lightning.qubit\", wires=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@qml.qnode(device=dev, interface=\"tf\")\n",
    "def circuit(inputs, weights):\n",
    "    for layer in range(weights.shape[0]):\n",
    "        # upload inputs in groups of 2 or 3(for Rot() gates)\n",
    "        for i in range(0, inputs.shape[-1], 2):\n",
    "            # qml.Rot(*tf.unstack(inputs[:, i: i + 3], axis=1), wires=0)\n",
    "            qml.RX(inputs[:,i], wires=0)\n",
    "            if (i+1 < inputs.shape[-1]):\n",
    "                qml.RZ(inputs[:,i+1], wires=0)\n",
    "        qml.Rot(*weights[layer], wires=0)\n",
    "    return qml.expval(qml.PauliZ(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.constant(np.random.random((3,3)))\n",
    "weights = tf.Variable(np.random.random((3,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Figure size 1500x200 with 1 Axes>, <Axes: >)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qml.draw_mpl(circuit, decimals=1)(inputs, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.85072976, 0.79221255, 0.4284486 ], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = circuit(inputs, weights)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DRLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self,circuit:qml.QNode,layers:int):\n",
    "        super().__init__()\n",
    "        self.circuit = circuit\n",
    "        self.qubits =  len(circuit.device.wires)\n",
    "        self.layers = layers\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.layer_weights = self.add_weight(\n",
    "            shape=(self.layers, 3),\n",
    "            initializer=tf.keras.initializers.RandomUniform(minval=-np.pi, maxval=np.pi, seed=None),\n",
    "            trainable=True\n",
    "        )\n",
    "        self.built = True\n",
    "    \n",
    "    def compute_output_shape(self,input_shape):\n",
    "        return (input_shape[0],)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        outputs = circuit(inputs, self.layer_weights)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feynman Equations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_dict = {\n",
    "    \"I.6.2\": {\n",
    "        \"vars\": 2,\n",
    "        \"f\": lambda x: tf.exp(-(x[:, 0]**2) / (2 * x[:, 1]**2)) / tf.sqrt(2 * np.pi * x[:, 1]**2),\n",
    "    },\n",
    "    \"I.6.2b\": {\n",
    "        \"vars\": 3,\n",
    "        \"f\": lambda x: tf.exp(-((x[:, 0] - x[:, 1])**2) / (2 * x[:, 2]**2)) / tf.sqrt(2 * np.pi * x[:, 2]**2),\n",
    "    },\n",
    "    \"I.9.18\": {\n",
    "        \"vars\": 6,\n",
    "        \"f\": lambda x: x[:, 0] / ((x[:, 1] - 1)**2 + (x[:, 2] - x[:, 3])**2 + (x[:, 4] - x[:, 5])**2),\n",
    "    },\n",
    "    \"I.12.11\": {\n",
    "        \"vars\": 2,\n",
    "        \"f\": lambda x: 1 + x[:, 0] * tf.sin(x[:, 1]),\n",
    "    },\n",
    "    \"I.13.12\": {\n",
    "        \"vars\": 2,\n",
    "        \"f\": lambda x: x[:, 0] * (1 / x[:, 1] - 1),\n",
    "    },\n",
    "    \"I.15.3x\": {\n",
    "        \"vars\": 2,\n",
    "        \"f\": lambda x: (1 - x[:, 0]) / tf.sqrt(1 - x[:, 1]**2),\n",
    "    },\n",
    "    \"I.16.6\": {\n",
    "        \"vars\": 2,\n",
    "        \"f\": lambda x: (x[:, 0] + x[:, 1]) / (1 + x[:, 0] * x[:, 1]),\n",
    "    },\n",
    "    \"I.18.4\": {\n",
    "        \"vars\": 2,\n",
    "        \"f\": lambda x: (1 + x[:, 0] * x[:, 1]) / (1 + x[:, 0]),\n",
    "    },\n",
    "    \"I.26.2\": {\n",
    "        \"vars\": 2,\n",
    "        \"f\": lambda x: tf.asin(x[:, 0] * tf.sin(x[:, 1])),\n",
    "    },\n",
    "    \"I.27.6\": {\n",
    "        \"vars\": 2,\n",
    "        \"f\": lambda x: 1 / (1 + x[:, 0] * x[:, 1]),\n",
    "    },\n",
    "    \"I.29.16\": {\n",
    "        \"vars\": 3,\n",
    "        \"f\": lambda x: tf.sqrt(1 + x[:, 0]**2 - 2 * x[:, 0] * tf.cos(x[:, 1] - x[:, 2])),\n",
    "    },\n",
    "    \"I.30.3\": {\n",
    "        \"vars\": 2,\n",
    "        \"f\": lambda x: tf.sin(x[:, 0] * x[:, 1] / 2)**2 / tf.sin(x[:, 1] / 2)**2,\n",
    "    },\n",
    "    \"I.30.5\": {\n",
    "        \"vars\": 2,\n",
    "        \"f\": lambda x: tf.asin(x[:, 0] / x[:, 1]),  # Clip values for asin\n",
    "    },\n",
    "    \"I.37.4\": {\n",
    "        \"vars\": 2,\n",
    "        \"f\": lambda x: 1 + x[:, 0] + 2 * tf.sqrt(x[:, 0]) * tf.cos(x[:, 1]),  # Ensure sqrt argument is non-negative\n",
    "    },\n",
    "    \"I.40.1\": {\n",
    "        \"vars\": 2,\n",
    "        \"f\": lambda x: x[:, 0] * tf.exp(-x[:, 1]),\n",
    "    },\n",
    "    \"I.44.4\": {\n",
    "        \"vars\": 2,\n",
    "        \"f\": lambda x: x[:, 0] * tf.math.log(x[:, 1]),  # Ensure log argument is positive\n",
    "    },\n",
    "    \"I.50.26\": {\n",
    "        \"vars\": 2,\n",
    "        \"f\": lambda x: tf.cos(x[:, 0]) + x[:, 1] * tf.cos(x[:, 0]) ** 2,\n",
    "    },\n",
    "    \"II.2.42\": {\n",
    "        \"vars\": 2,\n",
    "        \"f\": lambda x: (x[:, 0] - 1) * x[:, 1],\n",
    "    },\n",
    "    \"II.6.15a\": {\n",
    "        \"vars\": 3,\n",
    "        \"f\": lambda x: (1 / (4 * tf.constant(np.pi, dtype=tf.float64))) * x[:, 2] * tf.sqrt(x[:, 0] ** 2 + x[:, 1] ** 2),  # Ensure sqrt argument is non-negative\n",
    "    },\n",
    "    \"II.11.7\": {\n",
    "        \"vars\": 3,\n",
    "        \"f\": lambda x: x[:, 0] * (1 + x[:, 1] * tf.cos(x[:, 2])),\n",
    "    },\n",
    "    \"II.11.27\": {\n",
    "        \"vars\": 2,\n",
    "        \"f\": lambda x: x[:, 0] * x[:, 1] / (1 - x[:, 0] * x[:, 1] / 3),\n",
    "    },\n",
    "    \"II.35.18\": {\n",
    "        \"vars\": 2,\n",
    "        \"f\": lambda x: x[:, 0] / (tf.exp(x[:, 1]) - tf.exp(-x[:, 1])),\n",
    "    },\n",
    "    \"II.36.38\": {\n",
    "        \"vars\": 3,\n",
    "        \"f\": lambda x: x[:, 0] + x[:, 1] * x[:, 2],\n",
    "    },\n",
    "    \"II.38.3\": {\n",
    "        \"vars\": 2,\n",
    "        \"f\": lambda x: x[:, 0] / (x[:, 1]),\n",
    "    },\n",
    "    \"III.9.52\": {\n",
    "        \"vars\": 3,\n",
    "        \"f\": lambda x: x[:, 0] * (tf.sin((x[:, 1] - x[:, 2]) / 2) ** 2) / ((x[:, 1] - x[:, 2]) ** 2 / 2),\n",
    "    },\n",
    "    \"III.10.19\": {\n",
    "        \"vars\": 2,\n",
    "        \"f\": lambda x: tf.sqrt(1 + x[:, 0] ** 2 + x[:, 1] ** 2),\n",
    "    },\n",
    "    \"III.17.37\": {\n",
    "        \"vars\": 3,\n",
    "        \"f\": lambda x: x[:, 2] * (1 + x[:, 0] * tf.cos(x[:, 1])),\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = lambda x: np.exp(-(x[:, 0]**2) / (2 * x[:, 1]**2)) / np.sqrt(2 * np.pi * x[:, 1]**2)\n",
    "f = function_dict['I.16.6']['f']\n",
    "feature_dim = function_dict['I.16.6']['vars']\n",
    "\n",
    "# Generate random data\n",
    "x = np.random.uniform(-1, 1, (1000, feature_dim))\n",
    "y = f(x)\n",
    "\n",
    "# Normalize y to the range [-1, 1]\n",
    "y = 2 * (y - np.min(y)) / (np.max(y) - np.min(y)) - 1\n",
    "\n",
    "# Proper train-test split\n",
    "train_size = 800\n",
    "x_train, x_val = x[:train_size], x[train_size:]\n",
    "y_train, y_val = y[:train_size], y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"DR\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"DR\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dr_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DRLayer</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                 │            <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dr_layer (\u001b[38;5;33mDRLayer\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m)                 │            \u001b[38;5;34m15\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15</span> (60.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m15\u001b[0m (60.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15</span> (60.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m15\u001b[0m (60.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inp = Input(shape=(feature_dim,))\n",
    "out = DRLayer(circuit=circuit, layers=5)(inp)\n",
    "model = Model(inputs=inp, outputs=out, name=\"DR\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
    "mae_loss = tf.keras.losses.MeanAbsoluteError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "val_batch_size = 20\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(batch_size)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val)).batch(val_batch_size)\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "    \n",
    "    for step, (x_batch, y_batch) in enumerate(train_dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = model(x_batch, training=True)\n",
    "            loss = mae_loss(y_batch, predictions)\n",
    "\n",
    "        gradients = tape.gradient(loss, model.trainable_weights)\n",
    "        opt.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "        print(f\"Step {step + 1}, Batch Loss: {loss:.4f}\", end=\"\\r\")\n",
    "\n",
    "    val_loss = 0\n",
    "    val_steps = 0\n",
    "    for x_batch, y_batch in val_dataset:\n",
    "        val_predictions = model(x_batch, training=False)\n",
    "        val_loss += mae_loss(y_batch, val_predictions)\n",
    "        val_steps += 1\n",
    "    val_loss /= val_steps\n",
    "    print(f\"\\nValidation Loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions for the entire validation set\n",
    "val_predictions = []\n",
    "val_true = []\n",
    "\n",
    "for x_batch, y_batch in val_dataset:\n",
    "    preds = model(x_batch, training=False)\n",
    "    val_predictions.append(preds.numpy())\n",
    "    val_true.append(y_batch.numpy())\n",
    "\n",
    "# Concatenate all batches to form arrays\n",
    "val_predictions = np.concatenate(val_predictions, axis=0)\n",
    "val_predictions = (val_predictions + 1) * (np.max(y_train) - np.min(y_train)) / 2 + np.min(y_train)\n",
    "val_true = np.concatenate(val_true, axis=0)\n",
    "loss = mae_loss(val_predictions, val_true)\n",
    "\n",
    "# Create a 3D scatter plot\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Plot true values\n",
    "ax.scatter(x_val[:, 0], x_val[:, 1], val_true, color='blue', label='True Values', alpha=0.6)\n",
    "\n",
    "# Plot predicted values\n",
    "ax.scatter(x_val[:, 0], x_val[:, 1], val_predictions, color='red', label='Predictions', alpha=0.6)\n",
    "\n",
    "# Set labels and legend\n",
    "ax.set_xlabel('Feature 1 (x[:, 0])')\n",
    "ax.set_ylabel('Feature 2 (x[:, 1])')\n",
    "ax.set_zlabel('Output (y)')\n",
    "ax.set_title('3D Scatter Plot of True and Predicted Values (Validation Set)')\n",
    "ax.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop over all the eqn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_domain_I_30_5():\n",
    "    a = np.random.uniform(-1, 1, size=(1000, 1))\n",
    "    n = np.random.uniform(np.abs(a), 1, size=(1000, 1))\n",
    "    return np.hstack((a, n))\n",
    "\n",
    "def generate_domain_I_37_4():\n",
    "    a = np.random.uniform(0, 1, size=(1000, 1))  # x[0] >= 0\n",
    "    n = np.random.uniform(-np.pi, np.pi, size=(1000, 1))  # x[1] in [-π, π]\n",
    "    return np.hstack((a, n))\n",
    "\n",
    "def generate_domain_I_44_4():\n",
    "    a = np.random.uniform(-1, 1, size=(1000, 1))\n",
    "    n = np.random.uniform(1e-3, 1, size=(1000, 1))  # x[1] > 0\n",
    "    return np.hstack((a, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(function_id, feature_dim, generator_function):\n",
    "    if (function_id == \"I.30.5\"):\n",
    "        x = generate_domain_I_30_5()\n",
    "    elif (function_id == \"I.37.4\"):\n",
    "        x = generate_domain_I_37_4()\n",
    "    elif (function_id == \"I.44.4\"):\n",
    "        x = generate_domain_I_44_4()\n",
    "    else:\n",
    "        x = np.random.uniform(-1, 1, (1000, feature_dim))\n",
    "    y = generator_function(x)\n",
    "\n",
    "    # Normalize y to the range [-1, 1]\n",
    "    y = 2 * (y - np.min(y)) / (np.max(y) - np.min(y)) - 1\n",
    "    \n",
    "    train_size = 800\n",
    "    x_train, x_val = x[:train_size], x[train_size:]\n",
    "    y_train, y_val = y[:train_size], y[train_size:]\n",
    "    return x_train, x_val, y_train, y_val, np.min(y), np.max(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(circuit, feature_dim, layers):\n",
    "    inp = Input(shape=(feature_dim,))\n",
    "    out = DRLayer(circuit=circuit, layers=layers)(inp)\n",
    "    model = Model(inputs=inp, outputs=out, name=\"DR\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_loss(y_pred, y_true):\n",
    "    loss = tf.sqrt(tf.reduce_mean((y_pred - y_true)**2))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_loss = tf.keras.losses.MeanAbsoluteError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_function(x_train, x_val, y_train, y_val, y_min, y_max):\n",
    "    opt = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
    "    # loss_fn = mae_loss\n",
    "    loss_fn = rmse_loss\n",
    "\n",
    "    epochs = 10\n",
    "    batch_size = 20\n",
    "    val_batch_size = 20\n",
    "\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(batch_size)\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val)).batch(val_batch_size)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        \n",
    "        for step, (x_batch, y_batch) in enumerate(train_dataset):\n",
    "            with tf.GradientTape() as tape:\n",
    "                predictions = model(x_batch, training=True)\n",
    "                predictions = tf.cast(predictions, dtype=tf.float64)\n",
    "                # predictions = (predictions + 1) * (y_max - y_min) / 2 + y_min     # inverse rescaling\n",
    "                loss = loss_fn(y_batch, predictions)\n",
    "\n",
    "            gradients = tape.gradient(loss, model.trainable_weights)\n",
    "            opt.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "            print(f\"Step {step + 1}, Batch Loss: {loss:.4f}\", end=\"\\r\")\n",
    "\n",
    "        val_loss = 0\n",
    "        val_steps = 0\n",
    "        for x_batch, y_batch in val_dataset:\n",
    "            val_predictions = model(x_batch, training=False)\n",
    "            val_predictions = tf.cast(val_predictions, dtype=tf.float64)\n",
    "            # val_predictions = (val_predictions + 1) * (y_max - y_min) / 2 + y_min     # inverse rescaling\n",
    "            val_loss += loss_fn(y_batch, val_predictions)\n",
    "            val_steps += 1\n",
    "        val_loss /= val_steps\n",
    "        print(f\"\\nValidation Loss: {val_loss:.4f}\")\n",
    "    return model, val_loss.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for key, value in function_dict.items():\n",
    "    print(\"\\nTraining function \", key)\n",
    "    function_name = key\n",
    "    feature_dim = value['vars']\n",
    "    generator_function = value['f']\n",
    "    x_train, x_val, y_train, y_val, y_min, y_max = generate_dataset(function_name, feature_dim, generator_function)\n",
    "    model = build_model(circuit=circuit, feature_dim=feature_dim, layers=5)\n",
    "    model, final_loss = train_function(x_train, x_val, y_train, y_val, y_min, y_max)\n",
    "    results.append({\"Function\": function_name, \"Final Loss\": final_loss})\n",
    "    # break\n",
    "result_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_date = pd.Timestamp.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "result_df.to_csv(f\"results/feynman_vanilla_dr/results_{time_date}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DR code for univariate approximation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(x):\n",
    "    step.name = 'step'\n",
    "    return 0.5 * (np.sign(x) + 1)\n",
    "\n",
    "def sigmoid(x, a=10):\n",
    "    sigmoid.name = 'sigmoid'\n",
    "    return 1 / (1 + np.exp(-a * x))\n",
    "\n",
    "def tanh(x, a=5):\n",
    "    tanh.name = 'tanh'\n",
    "    return np.tanh(a * x)\n",
    "\n",
    "def relu(x):\n",
    "    relu.name = 'relu'\n",
    "    return x * (x > 0)\n",
    "\n",
    "def poly(x):\n",
    "    poly.name= 'poly'\n",
    "    return np.abs(3*x**3 * (1 - x**4))\n",
    "\n",
    "def func1(x):\n",
    "    func1.name = 'func1'\n",
    "    return np.exp(np.sin(x))/np.e\n",
    "\n",
    "def func2(x):\n",
    "    func2.name = 'func2'\n",
    "    return (0.01*(x**4) - 0.1*(x**3) + 3*x**2 - x - 10)/500\n",
    "\n",
    "def func3(x):\n",
    "    func3.name = 'func3'\n",
    "    return (np.exp(np.sin(x))*(x**3) + x**2)/1500\n",
    "\n",
    "def func4(x):\n",
    "    func4.name = 'func4'\n",
    "    return (np.exp(np.sin(x))*np.tanh(x**3) + (1-np.exp(np.cos(x)))*x**2)/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@qml.qnode(device=dev, interface=\"tf\")\n",
    "def circuit(inputs, weights):\n",
    "    for layer in range(weights.shape[0]):\n",
    "        # upload inputs in groups of 2 or 3(for Rot() gates)\n",
    "        for i in range(0, inputs.shape[-1], 2):\n",
    "            # qml.Rot(*tf.unstack(inputs[:, i: i + 3], axis=1), wires=0)\n",
    "            qml.RX(inputs[:,i], wires=0)\n",
    "            if (i+1 < inputs.shape[-1]):\n",
    "                qml.RZ(inputs[:,i+1], wires=0)\n",
    "        qml.Rot(*weights[layer], wires=0)\n",
    "    return qml.expval(qml.PauliZ(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @qml.qnode(device=dev, interface=\"tf\")\n",
    "# def circuit(inputs, weights):\n",
    "#     for layer in range(weights.shape[0]):\n",
    "#         # upload inputs in groups of 2 or 3(for Rot() gates)\n",
    "#         for i in range(0, inputs.shape[-1], 2):\n",
    "#             qml.RX(inputs[:,i], wires=0)\n",
    "#         qml.Rot(*weights[layer], wires=0)\n",
    "#     return qml.expval(qml.PauliZ(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DRLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self,circuit:qml.QNode,layers:int):\n",
    "        super().__init__()\n",
    "        self.circuit = circuit\n",
    "        self.qubits =  len(circuit.device.wires)\n",
    "        self.layers = layers\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.layer_weights = self.add_weight(\n",
    "            shape=(self.layers, 3),\n",
    "            initializer=tf.keras.initializers.RandomUniform(minval=-np.pi, maxval=np.pi, seed=None),\n",
    "            trainable=True\n",
    "        )\n",
    "        self.built = True\n",
    "    \n",
    "    def compute_output_shape(self,input_shape):\n",
    "        return (input_shape[0],)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        outputs = circuit(inputs, self.layer_weights)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_dataset():\n",
    "#     x = np.linspace(-1, 1, 100)\n",
    "#     y = poly(x)\n",
    "#     return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(func_name):\n",
    "    x = np.linspace(-1, 1, 100)\n",
    "    y = func_name(x)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(feature_dim, layers=5):\n",
    "    inp = Input(shape=(feature_dim,))\n",
    "    out = DRLayer(circuit=circuit, layers=layers)(inp)\n",
    "    model = Model(inputs=inp, outputs=out, name=\"DR\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_function(x_train, y_train, model, lossfn, opt, lossfn1, epochs=50):\n",
    "    for epoch in range(epochs + 1):\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = model(x_train, training=True)\n",
    "            loss = lossfn(y_train, predictions)\n",
    "        gradients = tape.gradient(loss, model.trainable_weights)\n",
    "        opt.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "        if(epoch%50==0):\n",
    "            plt.plot(x_train, y, label=\"True\")\n",
    "            plt.scatter(x_train,predictions, label=\"Predicted\", color='red', s=10)\n",
    "            plt.title(f\"DR Function epoch {epoch}\")\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "        print(f\"Epoch {epoch} | loss:{tf.reduce_mean(loss)}\",end=\"\\r\")\n",
    "    return float(tf.reduce_mean(loss).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_lr(epoch, total_epochs, lr_max, lr_min=1e-6):\n",
    "    \"\"\"Cosine decay learning-rate schedule.\"\"\"\n",
    "    return lr_min + 0.5 * (lr_max - lr_min) * (1 + np.cos(np.pi * epoch / total_epochs))\n",
    "\n",
    "def train_function(x_train, y_train, model, lossfn, opt, lossfn1=None,\n",
    "                   epochs=50, lr_max=1e-3, lr_min=1e-6):\n",
    "\n",
    "    for epoch in range(epochs + 1):\n",
    "\n",
    "        # ---- Update learning rate using cosine decay ----\n",
    "        new_lr = cosine_lr(epoch, epochs, lr_max, lr_min)\n",
    "        opt.learning_rate.assign(new_lr)\n",
    "\n",
    "        # ---- Forward + backward pass ----\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = model(x_train, training=True)\n",
    "            loss = lossfn(y_train, predictions)\n",
    "\n",
    "        gradients = tape.gradient(loss, model.trainable_weights)\n",
    "        opt.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "\n",
    "        # ---- Plot every 50 epochs ----\n",
    "        if epoch % 50 == 0:\n",
    "            plt.plot(x_train, y_train, label=\"True\")\n",
    "            plt.scatter(x_train, predictions, color='red', s=10, label=\"Predicted\")\n",
    "            plt.title(f\"DR Function - Epoch {epoch} | LR={new_lr:.6f}\")\n",
    "            plt.grid(True)\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "        print(f\"Epoch {epoch}/{epochs} | loss: {tf.reduce_mean(loss):.6f} | LR: {new_lr:.6e}\", end=\"\\r\")\n",
    "\n",
    "    return float(tf.reduce_mean(loss).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_function(x_train, y_train, model, lossfn, opt, lossfn1, epochs=50, opt1=None, opt2=None):\n",
    "    for epoch in range(epochs + 1):\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = model(x_train, training=True)\n",
    "            # if(epoch < 50):\n",
    "            #     loss = lossfn1(y_train, predictions)\n",
    "            # else:\n",
    "            #     loss = lossfn(y_train, predictions)\n",
    "            loss = lossfn(y_train, predictions)\n",
    "        gradients = tape.gradient(loss, model.trainable_weights)\n",
    "        if(epoch < 111):\n",
    "            opt.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "        elif(epoch < 181):\n",
    "            opt1.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "        else:\n",
    "            opt2.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "        if(epoch%50==0):\n",
    "            plt.plot(x_train, y, label=\"True\")\n",
    "            plt.scatter(x_train,predictions, label=\"Predicted\", color='red', s=10)\n",
    "            plt.title(f\"DR Function epoch {epoch}\")\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "        print(f\"Epoch {epoch} | loss:{tf.reduce_mean(loss)}\",end=\"\\r\")\n",
    "    return float(tf.reduce_mean(loss).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_inputs(x):\n",
    "    #x = np.divide(x, np.abs(np.max(x)))\n",
    "    #x = (x + 1) / 2\n",
    "    #x = np.multiply(x, np.pi)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_loss(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.abs(y_true - y_pred)**2)*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_loss(y_pred, y_true):\n",
    "    loss = tf.sqrt(tf.reduce_mean((y_pred - y_true)**2))*10\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(y_pred, y_true):\n",
    "    loss = tf.reduce_mean((y_pred - y_true)**2)*10\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "funname_dict={relu: \"relu\",\n",
    "              poly: \"poly\",\n",
    "              func1: \"func1\",\n",
    "              func2: \"func2\",\n",
    "              func3: \"func3\",\n",
    "              func4: \"func4\",\n",
    "              step: \"step\",\n",
    "              sigmoid: \"sigmoid\",\n",
    "              tanh: \"tanh\",\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "funname_dict={#poly: \"poly\",\n",
    "            #   func2: \"func2\",\n",
    "            #   func3: \"func3\",\n",
    "              # func4: \"func4\",\n",
    "              #step: \"step\",\n",
    "              # sigmoid: \"sigmoid\",\n",
    "              tanh: \"tanh\",\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = []\n",
    "for func, name in funname_dict.items():\n",
    "    print(f\"Training function {name}\")\n",
    "    x, y = create_dataset(func)\n",
    "    y = 2 * (y - np.min(y)) / (np.max(y) - np.min(y)) - 1\n",
    "    x_train = rescale_inputs(x)\n",
    "    model = build_model(1, 20)\n",
    "    opt  = tf.keras.optimizers.Adam(learning_rate=0.05)\n",
    "    opt1  = tf.keras.optimizers.Adam(learning_rate=0.04)\n",
    "    opt2  = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "    lossfn = rmse_loss\n",
    "    lossfn1 = rmse_loss\n",
    "    epochs = 400\n",
    "    # Train and get final loss (modify train_function to return final loss)\n",
    "    final_loss = train_function(x_train, y, model, lossfn, opt, lossfn1, epochs,opt1, opt2)\n",
    "    num_params = model.count_params()\n",
    "    results.append({\n",
    "        \"Function\": name,\n",
    "        \"Num_Params\": num_params,\n",
    "        \"Final_Loss\": float(final_loss) if hasattr(final_loss, 'numpy') else final_loss,\n",
    "        \"epochs\": epochs,\n",
    "        \"loss fun\": 'mae'\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Function': 'relu',\n",
       "  'Num_Params': 27,\n",
       "  'Final_Loss': 0.2838659882545471,\n",
       "  'epochs': 400,\n",
       "  'loss fun': 'mae'},\n",
       " {'Function': 'poly',\n",
       "  'Num_Params': 27,\n",
       "  'Final_Loss': 1.9040626287460327,\n",
       "  'epochs': 400,\n",
       "  'loss fun': 'mae'},\n",
       " {'Function': 'func1',\n",
       "  'Num_Params': 27,\n",
       "  'Final_Loss': 0.30459487438201904,\n",
       "  'epochs': 400,\n",
       "  'loss fun': 'mae'},\n",
       " {'Function': 'func2',\n",
       "  'Num_Params': 27,\n",
       "  'Final_Loss': 0.21385008096694946,\n",
       "  'epochs': 400,\n",
       "  'loss fun': 'mae'},\n",
       " {'Function': 'func3',\n",
       "  'Num_Params': 27,\n",
       "  'Final_Loss': 0.3301410675048828,\n",
       "  'epochs': 400,\n",
       "  'loss fun': 'mae'},\n",
       " {'Function': 'func4',\n",
       "  'Num_Params': 27,\n",
       "  'Final_Loss': 0.6834577918052673,\n",
       "  'epochs': 400,\n",
       "  'loss fun': 'mae'},\n",
       " {'Function': 'step',\n",
       "  'Num_Params': 27,\n",
       "  'Final_Loss': 2.595576286315918,\n",
       "  'epochs': 400,\n",
       "  'loss fun': 'mae'},\n",
       " {'Function': 'sigmoid',\n",
       "  'Num_Params': 27,\n",
       "  'Final_Loss': 0.2845478653907776,\n",
       "  'epochs': 400,\n",
       "  'loss fun': 'mae'},\n",
       " {'Function': 'tanh',\n",
       "  'Num_Params': 27,\n",
       "  'Final_Loss': 0.2889822721481323,\n",
       "  'epochs': 400,\n",
       "  'loss fun': 'mae'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Function</th>\n",
       "      <th>Num_Params</th>\n",
       "      <th>Final_Loss</th>\n",
       "      <th>epochs</th>\n",
       "      <th>loss fun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>relu</td>\n",
       "      <td>27</td>\n",
       "      <td>0.283866</td>\n",
       "      <td>400</td>\n",
       "      <td>mae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>poly</td>\n",
       "      <td>27</td>\n",
       "      <td>1.904063</td>\n",
       "      <td>400</td>\n",
       "      <td>mae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>func1</td>\n",
       "      <td>27</td>\n",
       "      <td>0.304595</td>\n",
       "      <td>400</td>\n",
       "      <td>mae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>func2</td>\n",
       "      <td>27</td>\n",
       "      <td>0.213850</td>\n",
       "      <td>400</td>\n",
       "      <td>mae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>func3</td>\n",
       "      <td>27</td>\n",
       "      <td>0.330141</td>\n",
       "      <td>400</td>\n",
       "      <td>mae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>func4</td>\n",
       "      <td>27</td>\n",
       "      <td>0.683458</td>\n",
       "      <td>400</td>\n",
       "      <td>mae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>step</td>\n",
       "      <td>27</td>\n",
       "      <td>2.595576</td>\n",
       "      <td>400</td>\n",
       "      <td>mae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>27</td>\n",
       "      <td>0.284548</td>\n",
       "      <td>400</td>\n",
       "      <td>mae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tanh</td>\n",
       "      <td>27</td>\n",
       "      <td>0.288982</td>\n",
       "      <td>400</td>\n",
       "      <td>mae</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Function  Num_Params  Final_Loss  epochs loss fun\n",
       "0     relu          27    0.283866     400      mae\n",
       "1     poly          27    1.904063     400      mae\n",
       "2    func1          27    0.304595     400      mae\n",
       "3    func2          27    0.213850     400      mae\n",
       "4    func3          27    0.330141     400      mae\n",
       "5    func4          27    0.683458     400      mae\n",
       "6     step          27    2.595576     400      mae\n",
       "7  sigmoid          27    0.284548     400      mae\n",
       "8     tanh          27    0.288982     400      mae"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = create_dataset(func1)\n",
    "model = build_model(1, 7)\n",
    "x_train = rescale_inputs(x)\n",
    "opt  = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "lossfn = mae_loss\n",
    "lossfn1= mae_loss\n",
    "train_function(x_train, y, model, lossfn, opt, lossfn1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
